-
  Q: What is a good way to productize and deploy a machine learning model, especially for NLP. #student #springboard #GuSu #20200602130000
  A: For NLP the entire pipeline should be provided to the development team to integrate into a production app and deploy. Sciki-Learn Pipeline objects can be pickled after you have a trained model and then this can be depickled within any other python application by your development team.
-
  Q: Is it important to normalize or standardize your feature and target variables before performing a fit? #student #springboard #EdLe #20200602150000
  A: Normalizing your dataset would have **NO** effect for an Ordinary Least Squares linear regression (`sklearn.LinearRegression`). For linear regression normalizing your data can make it more difficult to interpret and verify your results. However for many models, such as `LogisticRegression` or any other model performing regularization or feature selection internally, it is extremely important. For these models it can be critical to improving the accuracy of your model. Just remember to store the fitted `Scaler` object in a variable so you can later use it to inverse_transform the coefficients of your model to help you interpret and explain your results.
-
  Q: How should I deal with nan's in a datetime? #student #springboard #ElHo #20200602163000
  A: First clean up all the categorical and numerical variables in your dataset and build a model to predict your target variable.  Next, create a datetime_isna column to record the presence/absence of NaNs in your datetime column. Then you can try different `.fillna()` methods like `"mean"` or 0 and compare the accuracy of these models to the baseline and fill the nans with zeros and This gives you a baseline accuracy that you can compare your accuracy to after you've cleaned up the datetime columns. Then create a regression model that predicts datetime as a continuous value (such as seconds since 1970) using the rows where you have nonnan values. Do not use the target variable when you are predicting datetime. Finally, use that regression model to predict the NaN datetime values. Finally, train and validate a model trained on all your features including the datetime column and confirm that accuracy on your test set is no worse than before the fill method. You should also convirm that it is no worse than if you just fill the datetime with zeros or a mean.
-
  Q: When should I train my first model on my dataset? #student #springboard #YeHe #20200602170000
  A: As soon as you have at least one target variable and one feature variable cleaned up. A cleaned variable is one that has all numerical or boolean values without any NaNs or strings or object dtypes.
-
  Q: How can I consolidate my code for training models and tuning hyperparameters?  #student #springboard #SaSi #20200603090000
  A: "Try something like this at the beginning of your notebook: `hypertable = []`. Then for every model you train create a dictionary to contain the hyperparameters and the accuracy metrics: `hyperrow['model'] = model.__class__.__name__` and `hyperrow['testset_score'] = model.score(X_test, y_test)`."
-
  Q: What's a good dataset for contributing to governmental reform to combat racism. #student #springboard #GaLi #20200603093000
  A: This [collection of datasets](https://www.policedatainitiative.org/datasets/) contains police reports from various cities in the US.
-
  Q: Should I clean up all my data first or train a model. #student #springboard #AlDe #20200603100000
  A: I like to first train a model on the features that are already clean, such as all the numerical features that do not have missing or NaN values. That gives you a benchmark accuracy for a simple model. Then you can add more features as you clean them to see how your accuracy improves.
-
  Q: Should I filter outliers from my dataset before training a model? #student #springboard #HaSe #20200603103000
  A: Only if your stakeholders, the ones using your model in the real world, do not need to use that model to make predictions on data similar to that for your outliers.
-
  Q: Should I include double integrated (cumsum) accelerometer data in my model as a feature to predict sobriety? #student #springboard #MaDu #20200603113000
  A: Always include all feature variables, even if you are not sure whether they are relevant to your target variable. And position information derived from accelation is an especially good representation of data that often says a lot about the world, including whether people on a pub crawl are sober or not.
-
  Q: What is the residual for a machine learning model? #student #springboard #DaLo #20200603120000
  A: The signed error or the difference between the model predictions and the truth. For example `residual = y_test_pred - y_train_pred`. If you see any pattern like a U shape or curvature in the plots of residual vs any of your features, that's an indication that you could generate a new feature by squaring or taking the square root of that feature variable. #student #springboard #DaLo #20200603113000
-
  Q: Besides identifying which model was the best and what it's accuracy is what else should I include in my final report.
  A: You should also answer "why" questions rather than just "what" quations. Consider questions that two different audiences would ask, data scientists and business managers. Why should each of them care about your results. How can business managers use your results to improve their businesses. How can data scientists learn from your approach and apply it to future data science problems.
-
  Q: I have a categorical variable like gender or business segment as a feature in my model. Would it improve the accuracy of my model to build separate models for each category or class?
  A: No. It would be much better to engineer additional features from those categorical variables that multiply those categorical variables by some of the other features.
